{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#%pip install dask[dataframe] --upgrade\n",
    "#import dask.dataframe as dd\n",
    "#%pip install kaggle\n",
    "import kaggle\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "#this downloads the files to my home directory\n",
    "#i moved them to storage bucket using terminal after unzipping\n",
    "api = KaggleApi('kaggle.json')\n",
    "api.authenticate()\n",
    "api.competition_download_files(\"talkingdata-adtracking-fraud-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  test.csv.zip\n",
      "  inflating: test.csv                \n"
     ]
    }
   ],
   "source": [
    "#unzipping files\n",
    "!unzip test.csv.zip\n",
    "!unzip train.csv.zip\n",
    "!unzip train_sample.csv.zip\n",
    "!unzip sample_submission.csv.zip\n",
    "!unzip test.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the string below with a unique name for the new bucket\n",
    "bucket_name = \"talking-data-1\"\n",
    "\n",
    "# Replace the string below with your project ID\n",
    "project_id = \"gcp-test-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client created using default project: gcp-test-1-246001\n",
      "Bucket talking-data-1 created.\n"
     ]
    }
   ],
   "source": [
    "#Run the following to create a client with your default project:\n",
    "client = storage.Client()\n",
    "print(\"Client created using default project: {}\".format(client.project))\n",
    "\n",
    "# Creates the new bucket\n",
    "bucket = client.create_bucket(bucket_name)\n",
    "print(\"Bucket {} created.\".format(bucket.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets in gcp-test-1-246001:\n",
      "\ttalking-data-1\n"
     ]
    }
   ],
   "source": [
    "buckets = client.list_buckets()\n",
    "\n",
    "print(\"Buckets in {}:\".format(client.project))\n",
    "for item in buckets:\n",
    "    print(\"\\t\" + item.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket name: talking-data-1\n",
      "Bucket location: US\n",
      "Bucket storage class: STANDARD\n"
     ]
    }
   ],
   "source": [
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "print(\"Bucket name: {}\".format(bucket.name))\n",
    "print(\"Bucket location: {}\".format(bucket.location))\n",
    "print(\"Bucket storage class: {}\".format(bucket.storage_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://sample_submission.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://test.csv [Content-Type=text/csv]...\n",
      "Copying file://test_supplement.csv [Content-Type=text/csv]...\n",
      "|\n",
      "Operation completed over 3 objects/3.5 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "#transferring unzipped csv's to bucket storage\n",
    "!gsutil cp *.csv gs://talking-data-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://mnt/ssd/kaggle-talkingdata2/competition_files/train.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\\n",
      "Operation completed over 1 objects/7.0 GiB.                                      \n",
      "Copying file://mnt/ssd/kaggle-talkingdata2/competition_files/train_sample.csv [Content-Type=text/csv]...\n",
      "-\n",
      "Operation completed over 1 objects/3.9 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "#transferring unzipped csv's to bucket storage\n",
    "!gsutil cp mnt/ssd/kaggle-talkingdata2/competition_files/train.csv gs://talking-data-1/\n",
    "!gsutil cp mnt/ssd/kaggle-talkingdata2/competition_files/train_sample.csv gs://talking-data-1/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
